# Azure Kinect 캘리브레이션 및 테스트 기록

## 개요

| 항목 | 내용 |
|------|------|
| 프로젝트 | RoArm-M3-Pro State-based RL Sim2Real |
| 카메라 | Azure Kinect DK |
| 목적 | 카메라 좌표 → 로봇 좌표 변환 (Hand-Eye Calibration) |
| 시작일 | 2026-01-19 |

---

## 1. 캘리브레이션 방법

### 1.1 사용한 방식
- **Rigid Body Transformation**: `robot_pos = R @ camera_pos + t`
- **SVD 기반 최소제곱법**으로 회전 행렬 R과 이동 벡터 t 계산
- **마커 방식**: 로봇 그리퍼에 빨간색 펜 부착 → HSV 색상 감지

### 1.2 캘리브레이션 스크립트
```
E:\RoArm_Project\calibrate_azure_kinect.py
```

**조작법:**
- `S`: 현재 위치 저장 (카메라 좌표 + 로봇 좌표 자동 읽기)
- `D`: 마지막 점 삭제
- `R`: 모든 점 리셋
- `C`: 캘리브레이션 계산 및 저장
- `Q/ESC`: 종료

---

## 2. 캘리브레이션 결과 (2026-01-19)

### 2.1 수집된 포인트

| Point | 카메라 좌표 (m) | 로봇 좌표 (m) | 변환 오차 |
|-------|----------------|---------------|----------|
| 1 | (-0.0116, 0.4668, 0.4955) | (0.2484, 0.2026, 0.1171) | 1.96 cm |
| 2 | (-0.0440, 0.3760, 0.4787) | (0.2500, 0.2246, 0.0847) | 2.31 cm |
| 3 | (-0.1478, 0.3220, 0.4754) | (0.2538, 0.1767, 0.0263) | 1.82 cm |
| 4 | (-0.0810, 0.2467, 0.4275) | (0.2575, 0.2297, 0.0319) | 1.92 cm |

### 2.2 오차 통계

| 지표 | 값 |
|------|-----|
| **평균 오차** | 2.00 cm |
| **최대 오차** | 2.31 cm |
| **최소 오차** | 1.82 cm |
| **표준편차** | 0.18 cm |

### 2.3 변환 행렬

**회전 행렬 R:**
```
det(R) = 1.000000 (유효한 회전 행렬)
||R^T R - I|| = 0.000000 (직교 행렬 조건 만족)
```

**회전 각도 (Euler ZYX):**
| 축 | 각도 |
|----|------|
| Roll (X) | -54.6° |
| Pitch (Y) | 57.7° |
| Yaw (Z) | 106.9° |

**이동 벡터 t:**
```
t = [0.2558, 0.0379, -0.1367] m
```

### 2.4 캘리브레이션 품질 평가

✅ **캘리브레이션 품질 양호**
- 평균 오차 2.00 cm (목표 < 3 cm 달성)
- 회전 행렬 유효함

⚠️ **주의사항 - 좁은 범위 문제**

캘리브레이션 시 수집된 점들의 범위가 매우 좁음:

| 축 | 범위 | 값 |
|----|------|-----|
| 카메라 X | 0.136m | -0.148 ~ -0.012 m |
| 카메라 Y | 0.220m | 0.247 ~ 0.467 m |
| 카메라 Z | 0.068m | 0.427 ~ 0.495 m |
| **로봇 X** | **0.009m (0.9cm)** | 0.248 ~ 0.258 m |
| **로봇 Y** | **0.053m (5.3cm)** | 0.177 ~ 0.230 m |
| **로봇 Z** | **0.091m (9.1cm)** | 0.026 ~ 0.117 m |

---

## 3. 문제점 분석

### 3.1 발견된 문제

#### 문제 1: 좁은 캘리브레이션 범위
- **증상**: 로봇을 좁은 범위에서만 이동하여 캘리브레이션
- **원인**: 더 넓게 이동하면 오차가 급격히 증가
- **영향**: 캘리브레이션된 범위 밖에서는 정확도 보장 불가

#### 문제 2: pose_get() 정확도 문제
- **증상**: 로봇을 넓게 이동시키면 캘리브레이션 오차 증가
- **원인**: `pose_get()` 함수가 Forward Kinematics(FK) 기반
  - FK 계산은 조인트 각도 → 엔드이펙터 위치 변환
  - 기계적 오차, 백래시, 센서 오차 누적
  - 로봇이 멀리 움직일수록 오차 증가
- **증거**: 좁은 범위에서는 2cm 오차, 넓은 범위에서는 100cm+ 오차

```python
# roarm_sdk/generate.py - pose_get() 구현
def pose_get(self):
    value = self.feedback_get()  # 조인트 피드백
    # FK로 계산된 값 반환
    poses = value[0:4]  # x, y, z, wrist_tilt
    return poses
```

#### 문제 3: 배경 빨간색 물체 오감지 (해결됨)
- **증상**: 배경의 빨간색 물체를 마커로 오인
- **해결**: 깊이 필터 추가 (0.2m ~ 0.8m 작업 영역만)

### 3.2 문제 영향

| 상황 | 예상 정확도 |
|------|------------|
| 캘리브레이션 범위 내 (~20cm 전방, ±3cm 좌우) | ~2 cm |
| 캘리브레이션 범위 밖 | 정확도 보장 불가 |

---

## 4. 수정 및 개선 사항

### 4.1 완료된 수정

#### 수정 1: 깊이 필터 추가
```python
# 깊이 필터: 로봇 작업 영역만 (0.2m ~ 0.8m)
depth_mask = (depth > 200) & (depth < 800)  # mm 단위
mask = mask & depth_mask.astype(np.uint8) * 255
```

#### 수정 2: 마지막 점 삭제 기능 (D키)
```python
def delete_last_point(self):
    if len(self.camera_points) == 0:
        print("삭제할 점이 없습니다!")
        return False
    self.camera_points.pop()
    self.robot_points.pop()
```

#### 수정 3: 전체 리셋 기능 (R키)
```python
def clear_all_points(self):
    self.camera_points = []
    self.robot_points = []
```

### 4.2 향후 개선 방향

#### 방향 1: 좁은 영역 전용으로 사용 (권장)
- 현재 캘리브레이션 그대로 사용
- 물체를 캘리브레이션된 범위 내에 배치
- 가장 빠른 방법, 2cm 정확도 달성

#### 방향 2: 수동 좌표 입력
- 줄자로 실제 로봇 그리퍼 위치 측정
- pose_get() 대신 수동 입력
- 더 정확하지만 번거로움

#### 방향 3: 체커보드 캘리브레이션
- 로봇 베이스에 체커보드 고정
- 더 정밀한 변환 행렬 계산 가능
- 추가 구현 필요

---

## 5. 물체 감지 테스트

### 5.1 테스트 스크립트
```
E:\RoArm_Project\test_object_detection.py
```

### 5.2 테스트 방법
1. 빨간색 물체를 캘리브레이션 범위 내에 배치
2. 스크립트 실행 (30초 테스트)
3. 변환된 로봇 좌표 확인
4. 실제 물체 위치와 비교

### 5.3 테스트 결과 (2026-01-19)

#### 기본 통계

| 항목 | 값 |
|------|-----|
| 총 테스트 시간 | 30.0초 |
| 총 프레임 수 | 903 |
| 감지 횟수 | 775 |
| **감지율** | **85.8%** |
| 평균 FPS | 30.1 |

#### 감지된 로봇 좌표 범위

| 축 | 감지 범위 | 평균 | 표준편차 |
|----|----------|------|---------|
| X | 21.8 ~ 28.0 cm | 25.3 cm | 1.61 cm |
| Y | -7.6 ~ 7.3 cm | 0.7 cm | 2.60 cm |
| Z | 21.2 ~ 36.7 cm | 27.4 cm | 4.18 cm |

#### 캘리브레이션 범위 비교

| 축 | 캘리브레이션 범위 | 감지된 범위 | 문제 |
|----|-----------------|------------|------|
| X | 20.3 ~ 21.2 cm (0.9cm) | 21.8 ~ 28.0 cm (6.2cm) | **범위 초과** |
| Y | 0.2 ~ 2.8 cm (2.6cm) | -7.6 ~ 7.3 cm (14.9cm) | **범위 초과** |
| Z | 22.4 ~ 30.9 cm (8.5cm) | 21.2 ~ 36.7 cm (15.5cm) | 부분 초과 |

#### 결과 분석

⚠️ **캘리브레이션 범위 내 감지: 348/775 (44.9%)**

**문제점:**
- 감지된 물체의 55%가 캘리브레이션 범위 밖
- 특히 Y축이 심각: 캘리브레이션 범위 2.6cm vs 감지 범위 14.9cm
- 넓은 범위에서 좌표 변환 정확도 보장 불가

**스크린샷 분석:**
| 이미지 | 카메라 좌표 (m) | 로봇 좌표 (m) | 비고 |
|--------|----------------|---------------|------|
| 1 | (-0.063, 0.086, 0.290) | (0.291, 0.072, 0.249) | 손 감지 |
| 2 | (-0.114, 0.034, 0.296) | (0.255, 0.018, 0.282) | 그리퍼 부근 |
| 3 | (-0.126, 0.073, 0.311) | (0.266, 0.010, 0.242) | 빨간 펜 감지 |

**관찰:**
- 빨간색 펜뿐 아니라 손의 피부색도 일부 감지됨
- 로봇 좌표 X는 약 25~29cm로 안정적
- Y, Z는 물체 위치에 따라 변동

---

## 6. 관련 파일

| 파일 | 용도 |
|------|------|
| `calibrate_azure_kinect.py` | 캘리브레이션 수행 |
| `verify_calibration.py` | 캘리브레이션 결과 검증 |
| `test_object_detection.py` | 물체 감지 테스트 |
| `calibration.npz` | 저장된 캘리브레이션 데이터 |

---

## 7. 결론 및 권장사항

### 7.1 현재 상태 요약

| 항목 | 상태 | 비고 |
|------|------|------|
| 물체 감지 | ✅ 동작 | 85.8% 감지율, 30 FPS |
| 좌표 변환 | ⚠️ 제한적 | 좁은 범위에서만 정확 |
| 캘리브레이션 | ⚠️ 재수행 필요 | 범위가 너무 좁음 |

### 7.2 권장 조치

#### 옵션 A: 캘리브레이션 재수행 (권장)
```
1. 로봇을 더 넓은 범위로 이동하며 8~10개 점 수집
2. X: ±5cm, Y: ±5cm, Z: ±10cm 범위 확보
3. pose_get() 부정확 시 수동 측정 병행
```

#### 옵션 B: 좁은 영역 전용 사용
```
1. 물체를 캘리브레이션 범위 내에만 배치
   - X: 20~21cm 전방
   - Y: 0~3cm 중앙
   - Z: 22~31cm 높이
2. 작업 영역 제한하여 사용
```

#### 옵션 C: 색상 필터 개선
```
1. 피부색 오감지 방지를 위해 HSV 범위 조정
2. 마커 크기 필터 강화
3. 특정 색상의 물체만 사용 (형광 빨강 등)
```

### 7.3 다음 단계

1. [x] 물체 감지 테스트 실행 및 결과 기록
2. [ ] **캘리브레이션 재수행** (더 넓은 범위, 8+ 점)
3. [ ] 캘리브레이션 범위 내에서 정확도 재검증
4. [ ] Sim2Real 파이프라인에 통합
5. [ ] 실제 로봇 동작 테스트

---

*마지막 업데이트: 2026-01-19*
